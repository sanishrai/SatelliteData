{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         140.5625  55.68378214  -0.234571412  -0.699648398  3.199832776  \\\n",
       "0      102.507812    58.882430      0.465318     -0.515088     1.677258   \n",
       "1      103.015625    39.341649      0.323328      1.051164     3.121237   \n",
       "2      136.750000    57.178449     -0.068415     -0.636238     3.642977   \n",
       "3       88.726562    40.672225      0.600866      1.123492     1.178930   \n",
       "4       93.570312    46.698114      0.531905      0.416721     1.636288   \n",
       "...           ...          ...           ...           ...          ...   \n",
       "17892  136.429688    59.847421     -0.187846     -0.738123     1.296823   \n",
       "17893  122.554688    49.485605      0.127978      0.323061    16.409699   \n",
       "17894  119.335938    59.935939      0.159363     -0.743025    21.430602   \n",
       "17895  114.507812    53.902400      0.201161     -0.024789     1.946488   \n",
       "17896   57.062500    85.797340      1.406391      0.089520   188.306020   \n",
       "\n",
       "       19.11042633  7.975531794  74.24222492  0  \n",
       "0        14.860146    10.576487   127.393580  0  \n",
       "1        21.744669     7.735822    63.171909  0  \n",
       "2        20.959280     6.896499    53.593661  0  \n",
       "3        11.468720    14.269573   252.567306  0  \n",
       "4        14.545074    10.621748   131.394004  0  \n",
       "...            ...          ...          ... ..  \n",
       "17892    12.166062    15.450260   285.931022  0  \n",
       "17893    44.626893     2.945244     8.297092  0  \n",
       "17894    58.872000     2.499517     4.595173  0  \n",
       "17895    13.381731    10.007967   134.238910  0  \n",
       "17896    64.712562    -1.597527     1.429475  0  \n",
       "\n",
       "[17897 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>140.5625</th>\n      <th>55.68378214</th>\n      <th>-0.234571412</th>\n      <th>-0.699648398</th>\n      <th>3.199832776</th>\n      <th>19.11042633</th>\n      <th>7.975531794</th>\n      <th>74.24222492</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>102.507812</td>\n      <td>58.882430</td>\n      <td>0.465318</td>\n      <td>-0.515088</td>\n      <td>1.677258</td>\n      <td>14.860146</td>\n      <td>10.576487</td>\n      <td>127.393580</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103.015625</td>\n      <td>39.341649</td>\n      <td>0.323328</td>\n      <td>1.051164</td>\n      <td>3.121237</td>\n      <td>21.744669</td>\n      <td>7.735822</td>\n      <td>63.171909</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>136.750000</td>\n      <td>57.178449</td>\n      <td>-0.068415</td>\n      <td>-0.636238</td>\n      <td>3.642977</td>\n      <td>20.959280</td>\n      <td>6.896499</td>\n      <td>53.593661</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>88.726562</td>\n      <td>40.672225</td>\n      <td>0.600866</td>\n      <td>1.123492</td>\n      <td>1.178930</td>\n      <td>11.468720</td>\n      <td>14.269573</td>\n      <td>252.567306</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93.570312</td>\n      <td>46.698114</td>\n      <td>0.531905</td>\n      <td>0.416721</td>\n      <td>1.636288</td>\n      <td>14.545074</td>\n      <td>10.621748</td>\n      <td>131.394004</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17892</th>\n      <td>136.429688</td>\n      <td>59.847421</td>\n      <td>-0.187846</td>\n      <td>-0.738123</td>\n      <td>1.296823</td>\n      <td>12.166062</td>\n      <td>15.450260</td>\n      <td>285.931022</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17893</th>\n      <td>122.554688</td>\n      <td>49.485605</td>\n      <td>0.127978</td>\n      <td>0.323061</td>\n      <td>16.409699</td>\n      <td>44.626893</td>\n      <td>2.945244</td>\n      <td>8.297092</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17894</th>\n      <td>119.335938</td>\n      <td>59.935939</td>\n      <td>0.159363</td>\n      <td>-0.743025</td>\n      <td>21.430602</td>\n      <td>58.872000</td>\n      <td>2.499517</td>\n      <td>4.595173</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17895</th>\n      <td>114.507812</td>\n      <td>53.902400</td>\n      <td>0.201161</td>\n      <td>-0.024789</td>\n      <td>1.946488</td>\n      <td>13.381731</td>\n      <td>10.007967</td>\n      <td>134.238910</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17896</th>\n      <td>57.062500</td>\n      <td>85.797340</td>\n      <td>1.406391</td>\n      <td>0.089520</td>\n      <td>188.306020</td>\n      <td>64.712562</td>\n      <td>-1.597527</td>\n      <td>1.429475</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>17897 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "# this is another attempt at messing with the pulsar data\n",
    "# after going thorugh the sklearn tutorial and the pandas tutorial\n",
    "import pandas as pd\n",
    "data_frame = pd.read_csv('HTRU_2.csv')\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Mean of Int. Prof.  Stand. Deviation of Int. Prof.  \\\n",
       "0              102.507812                       58.882430   \n",
       "1              103.015625                       39.341649   \n",
       "2              136.750000                       57.178449   \n",
       "3               88.726562                       40.672225   \n",
       "4               93.570312                       46.698114   \n",
       "...                   ...                             ...   \n",
       "17892          136.429688                       59.847421   \n",
       "17893          122.554688                       49.485605   \n",
       "17894          119.335938                       59.935939   \n",
       "17895          114.507812                       53.902400   \n",
       "17896           57.062500                       85.797340   \n",
       "\n",
       "       Excess Kurtosis of Int. Prof.  Skewness of Int. Prof.  Mean of Curve  \\\n",
       "0                           0.465318               -0.515088       1.677258   \n",
       "1                           0.323328                1.051164       3.121237   \n",
       "2                          -0.068415               -0.636238       3.642977   \n",
       "3                           0.600866                1.123492       1.178930   \n",
       "4                           0.531905                0.416721       1.636288   \n",
       "...                              ...                     ...            ...   \n",
       "17892                      -0.187846               -0.738123       1.296823   \n",
       "17893                       0.127978                0.323061      16.409699   \n",
       "17894                       0.159363               -0.743025      21.430602   \n",
       "17895                       0.201161               -0.024789       1.946488   \n",
       "17896                       1.406391                0.089520     188.306020   \n",
       "\n",
       "        Stand. Deviation of Curve  Excess Kurtosis of Curve  \\\n",
       "0                       14.860146                 10.576487   \n",
       "1                       21.744669                  7.735822   \n",
       "2                       20.959280                  6.896499   \n",
       "3                       11.468720                 14.269573   \n",
       "4                       14.545074                 10.621748   \n",
       "...                           ...                       ...   \n",
       "17892                   12.166062                 15.450260   \n",
       "17893                   44.626893                  2.945244   \n",
       "17894                   58.872000                  2.499517   \n",
       "17895                   13.381731                 10.007967   \n",
       "17896                   64.712562                 -1.597527   \n",
       "\n",
       "       Skewness of Curve  Class  \n",
       "0             127.393580      0  \n",
       "1              63.171909      0  \n",
       "2              53.593661      0  \n",
       "3             252.567306      0  \n",
       "4             131.394004      0  \n",
       "...                  ...    ...  \n",
       "17892         285.931022      0  \n",
       "17893           8.297092      0  \n",
       "17894           4.595173      0  \n",
       "17895         134.238910      0  \n",
       "17896           1.429475      0  \n",
       "\n",
       "[17897 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean of Int. Prof.</th>\n      <th>Stand. Deviation of Int. Prof.</th>\n      <th>Excess Kurtosis of Int. Prof.</th>\n      <th>Skewness of Int. Prof.</th>\n      <th>Mean of Curve</th>\n      <th>Stand. Deviation of Curve</th>\n      <th>Excess Kurtosis of Curve</th>\n      <th>Skewness of Curve</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>102.507812</td>\n      <td>58.882430</td>\n      <td>0.465318</td>\n      <td>-0.515088</td>\n      <td>1.677258</td>\n      <td>14.860146</td>\n      <td>10.576487</td>\n      <td>127.393580</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103.015625</td>\n      <td>39.341649</td>\n      <td>0.323328</td>\n      <td>1.051164</td>\n      <td>3.121237</td>\n      <td>21.744669</td>\n      <td>7.735822</td>\n      <td>63.171909</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>136.750000</td>\n      <td>57.178449</td>\n      <td>-0.068415</td>\n      <td>-0.636238</td>\n      <td>3.642977</td>\n      <td>20.959280</td>\n      <td>6.896499</td>\n      <td>53.593661</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>88.726562</td>\n      <td>40.672225</td>\n      <td>0.600866</td>\n      <td>1.123492</td>\n      <td>1.178930</td>\n      <td>11.468720</td>\n      <td>14.269573</td>\n      <td>252.567306</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93.570312</td>\n      <td>46.698114</td>\n      <td>0.531905</td>\n      <td>0.416721</td>\n      <td>1.636288</td>\n      <td>14.545074</td>\n      <td>10.621748</td>\n      <td>131.394004</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17892</th>\n      <td>136.429688</td>\n      <td>59.847421</td>\n      <td>-0.187846</td>\n      <td>-0.738123</td>\n      <td>1.296823</td>\n      <td>12.166062</td>\n      <td>15.450260</td>\n      <td>285.931022</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17893</th>\n      <td>122.554688</td>\n      <td>49.485605</td>\n      <td>0.127978</td>\n      <td>0.323061</td>\n      <td>16.409699</td>\n      <td>44.626893</td>\n      <td>2.945244</td>\n      <td>8.297092</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17894</th>\n      <td>119.335938</td>\n      <td>59.935939</td>\n      <td>0.159363</td>\n      <td>-0.743025</td>\n      <td>21.430602</td>\n      <td>58.872000</td>\n      <td>2.499517</td>\n      <td>4.595173</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17895</th>\n      <td>114.507812</td>\n      <td>53.902400</td>\n      <td>0.201161</td>\n      <td>-0.024789</td>\n      <td>1.946488</td>\n      <td>13.381731</td>\n      <td>10.007967</td>\n      <td>134.238910</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17896</th>\n      <td>57.062500</td>\n      <td>85.797340</td>\n      <td>1.406391</td>\n      <td>0.089520</td>\n      <td>188.306020</td>\n      <td>64.712562</td>\n      <td>-1.597527</td>\n      <td>1.429475</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>17897 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# need to add column names\n",
    "data_frame.columns =['Mean of Int. Prof.', 'Stand. Deviation of Int. Prof.', \n",
    "                     'Excess Kurtosis of Int. Prof.', 'Skewness of Int. Prof.',\n",
    "                     'Mean of Curve', ' Stand. Deviation of Curve', 'Excess Kurtosis of Curve',\n",
    "                     'Skewness of Curve', 'Class']\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(17897, 8)\n(17897, 1)\n13014\n1303\n"
     ]
    }
   ],
   "source": [
    "# I already know from previous scannings of this dataset that it is fairly clean\n",
    "# I want to use some prewritten algorithms from sklearn to see which general algorithm will work better\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data_frame.copy()\n",
    "x.drop(['Class'], axis=1, inplace=True)\n",
    "y = data_frame.copy()\n",
    "y.drop(['Mean of Int. Prof.', 'Stand. Deviation of Int. Prof.', \n",
    "                     'Excess Kurtosis of Int. Prof.', 'Skewness of Int. Prof.',\n",
    "                     'Mean of Curve', ' Stand. Deviation of Curve', 'Excess Kurtosis of Curve',\n",
    "                     'Skewness of Curve'], axis=1, inplace=True)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=.2, random_state=1)\n",
    "\n",
    "print(len(y_train[y_train.Class == 0]))\n",
    "print(len(y_train[y_train.Class == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14317, 9)\n(13014, 9)\n(1303, 9)\n(1303, 9)\n(2606, 9)\n(2606, 8)\n(2606, 1)\n"
     ]
    }
   ],
   "source": [
    "# obviously not evenly distributed, I want to test out training on both evenly distributed and this distribution\n",
    "\n",
    "train_data = x_train.copy()\n",
    "train_data['Class'] = y_train\n",
    "print(train_data.shape)\n",
    "\n",
    "train_data_non_pulsar = train_data[train_data['Class'] == 0]\n",
    "train_data_pulsar = train_data[train_data['Class'] == 1]\n",
    "\n",
    "print(train_data_non_pulsar.shape) # this matches YAY\n",
    "print(train_data_pulsar.shape)\n",
    "\n",
    "#shuffle the non pulsar data\n",
    "from sklearn.utils import shuffle\n",
    "train_data_non_pulsar = shuffle(train_data_non_pulsar)\n",
    "\n",
    "#cut to same size as pulsar data\n",
    "train_data_non_pulsar = train_data_non_pulsar[:1303]\n",
    "print(train_data_non_pulsar.shape)\n",
    "\n",
    "train_data_balanced = train_data_non_pulsar.append(train_data_pulsar)\n",
    "train_data_balanced = shuffle(train_data_balanced)\n",
    "print(train_data_balanced.shape)\n",
    "train_data_balanced[:10]\n",
    "\n",
    "x_train_balanced = train_data_balanced.copy()\n",
    "x_train_balanced.drop(['Class'], axis=1, inplace=True)\n",
    "y_train_balanced = train_data_balanced.copy()\n",
    "y_train_balanced.drop(['Mean of Int. Prof.', 'Stand. Deviation of Int. Prof.', \n",
    "                     'Excess Kurtosis of Int. Prof.', 'Skewness of Int. Prof.',\n",
    "                     'Mean of Curve', ' Stand. Deviation of Curve', 'Excess Kurtosis of Curve',\n",
    "                     'Skewness of Curve'], axis=1, inplace=True)\n",
    "\n",
    "print(x_train_balanced.shape)\n",
    "print(y_train_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Unbalanced: \n",
      "Accuracy Score: 0.9756983240223464\n",
      "Confusion Matrix: \n",
      "[[3224   20]\n",
      " [  67  269]]\n",
      "F1 Score: [0.98668707 0.8608    ]\n",
      "Balanced:\n",
      "Accuracy Score: 0.9662011173184357\n",
      "Confusion Matrix: \n",
      "[[3152   92]\n",
      " [  29  307]]\n",
      "F1 Score: [0.98116732 0.83537415]\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# now we can train ( will train on both balanced and unbalanced but test on same test group )\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "logistic_regression.fit(x_train, y_train)\n",
    "y_predict = logistic_regression.predict(x_test)\n",
    "\n",
    "print(\"Unbalanced: \")\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))\n",
    "\n",
    "print(\"Balanced:\")\n",
    "logistic_regression.fit(x_train_balanced, y_train_balanced)\n",
    "y_predict = logistic_regression.predict(x_test)\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unbalanced: \nAccuracy Score: 0.7656424581005586\nConfusion Matrix: \n[[2738  506]\n [ 333    3]]\nF1 Score: [0.86714173 0.00710059]\nBalanced:\nAccuracy Score: 0.6511173184357542\nConfusion Matrix: \n[[2012 1232]\n [  17  319]]\nF1 Score: [0.76313294 0.33810281]\n"
     ]
    }
   ],
   "source": [
    "# K Means clustering.... This was very bad\r\n",
    "from sklearn.cluster import KMeans\r\n",
    "k_means = KMeans(n_clusters=2, random_state=0)\r\n",
    "\r\n",
    "k_means.fit(x_train, y_train)\r\n",
    "y_predict = k_means.predict(x_test)\r\n",
    "\r\n",
    "print(\"Unbalanced: \")\r\n",
    "print(\"Accuracy Score:\", end = \" \")\r\n",
    "print(accuracy_score(y_test, y_predict))\r\n",
    "print(\"Confusion Matrix: \")\r\n",
    "print(confusion_matrix(y_test, y_predict))\r\n",
    "print(\"F1 Score:\", end =\" \")\r\n",
    "print(f1_score(y_test, y_predict, average=None))\r\n",
    "\r\n",
    "print(\"Balanced:\")\r\n",
    "k_means.fit(x_train_balanced, y_train_balanced)\r\n",
    "y_predict = k_means.predict(x_test)\r\n",
    "print(\"Accuracy Score:\", end = \" \")\r\n",
    "print(accuracy_score(y_test, y_predict))\r\n",
    "print(\"Confusion Matrix: \")\r\n",
    "print(confusion_matrix(y_test, y_predict))\r\n",
    "print(\"F1 Score:\", end =\" \")\r\n",
    "print(f1_score(y_test, y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unbalanced: \nAccuracy Score: 0.96731843575419\nConfusion Matrix: \n[[3190   54]\n [  63  273]]\nF1 Score: [0.98199169 0.82352941]\nBalanced:\nAccuracy Score: 0.903072625698324\nConfusion Matrix: \n[[2933  311]\n [  36  300]]\nF1 Score: [0.94414936 0.63357973]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_predict = decision_tree.predict(x_test)\n",
    "\n",
    "print(\"Unbalanced: \")\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))\n",
    "\n",
    "print(\"Balanced:\")\n",
    "decision_tree.fit(x_train_balanced, y_train_balanced)\n",
    "y_predict = decision_tree.predict(x_test)\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Unbalanced: \n",
      "Accuracy Score: 0.9069832402234637\n",
      "Confusion Matrix: \n",
      "[[3243    1]\n",
      " [ 332    4]]\n",
      "F1 Score: [0.95116586 0.02346041]\n",
      "Balanced:\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Accuracy Score: 0.6483240223463688\n",
      "Confusion Matrix: \n",
      "[[2007 1237]\n",
      " [  22  314]]\n",
      "F1 Score: [0.76123649 0.33280339]\n"
     ]
    }
   ],
   "source": [
    "# SVC not great either\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(gamma='auto')\n",
    "\n",
    "svc.fit(x_train, y_train)\n",
    "y_predict = svc.predict(x_test)\n",
    "\n",
    "print(\"Unbalanced: \")\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))\n",
    "\n",
    "print(\"Balanced:\")\n",
    "svc.fit(x_train_balanced, y_train_balanced)\n",
    "y_predict = svc.predict(x_test)\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Unbalanced: \n",
      "Accuracy Score: 0.9692737430167597\n",
      "Confusion Matrix: \n",
      "[[3208   36]\n",
      " [  74  262]]\n",
      "F1 Score: [0.98314435 0.82649842]\n",
      "Balanced:\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Accuracy Score: 0.9603351955307262\n",
      "Confusion Matrix: \n",
      "[[3136  108]\n",
      " [  34  302]]\n",
      "F1 Score: [0.97786093 0.80965147]\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "neural_network = MLPClassifier(hidden_layer_sizes=(10,10,10))\n",
    "\n",
    "neural_network.fit(x_train, y_train)\n",
    "y_predict = neural_network.predict(x_test)\n",
    "\n",
    "print(\"Unbalanced: \")\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))\n",
    "\n",
    "print(\"Balanced:\")\n",
    "neural_network.fit(x_train_balanced, y_train_balanced)\n",
    "y_predict = neural_network.predict(x_test)\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}