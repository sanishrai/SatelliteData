{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2c8ae7b7397383be484f509670a744b7a75aaa69a8c48f2fc2b876db86f77bea"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     140.5625  55.68378214  -0.234571412  ...  7.975531794  74.24222492  0\n",
       "0  102.507812    58.882430      0.465318  ...    10.576487   127.393580  0\n",
       "1  103.015625    39.341649      0.323328  ...     7.735822    63.171909  0\n",
       "2  136.750000    57.178449     -0.068415  ...     6.896499    53.593661  0\n",
       "3   88.726562    40.672225      0.600866  ...    14.269573   252.567306  0\n",
       "4   93.570312    46.698114      0.531905  ...    10.621748   131.394004  0\n",
       "\n",
       "[5 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>140.5625</th>\n      <th>55.68378214</th>\n      <th>-0.234571412</th>\n      <th>-0.699648398</th>\n      <th>3.199832776</th>\n      <th>19.11042633</th>\n      <th>7.975531794</th>\n      <th>74.24222492</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>102.507812</td>\n      <td>58.882430</td>\n      <td>0.465318</td>\n      <td>-0.515088</td>\n      <td>1.677258</td>\n      <td>14.860146</td>\n      <td>10.576487</td>\n      <td>127.393580</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103.015625</td>\n      <td>39.341649</td>\n      <td>0.323328</td>\n      <td>1.051164</td>\n      <td>3.121237</td>\n      <td>21.744669</td>\n      <td>7.735822</td>\n      <td>63.171909</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>136.750000</td>\n      <td>57.178449</td>\n      <td>-0.068415</td>\n      <td>-0.636238</td>\n      <td>3.642977</td>\n      <td>20.959280</td>\n      <td>6.896499</td>\n      <td>53.593661</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>88.726562</td>\n      <td>40.672225</td>\n      <td>0.600866</td>\n      <td>1.123492</td>\n      <td>1.178930</td>\n      <td>11.468720</td>\n      <td>14.269573</td>\n      <td>252.567306</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93.570312</td>\n      <td>46.698114</td>\n      <td>0.531905</td>\n      <td>0.416721</td>\n      <td>1.636288</td>\n      <td>14.545074</td>\n      <td>10.621748</td>\n      <td>131.394004</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# This is a cleaned up version of my code to teach/present with\n",
    "# and/or be used as a template for learning\n",
    "\n",
    "# This allows you to do absolute paths to files This method returns your current working directory\n",
    "# This can be joined with the relative path to use absolute paths to files \n",
    "# (helpful with buggy pickles but we'll get to that later)\n",
    "import os\n",
    "here = os.getcwd()\n",
    "\n",
    "# I use pandas dataframes to store my data.abs\n",
    "# Just think of dataframes as a really convenient way to store 2D arrays\n",
    "# These dataframes give us helpful methods to manipulate data as well\n",
    "\n",
    "# as pd lets us abbriviate so we don't have to type pandas everytime we use one of its methods\n",
    "import pandas as pd \n",
    "\n",
    "# This opens up the csv file HTRU_2.csv and saves it into a dataframe that we can use to manipulate\n",
    "# this dataframe can be downloaded from the following link: \n",
    "# https://www.kaggle.com/charitarth/pulsar-dataset-htru2\n",
    "# The folks that created this dataset requested if we use it in work to cite the following:\n",
    "\"\"\"\n",
    "R. J. Lyon, B. W. Stappers, S. Cooper, J. M. Brooke, J. D. Knowles, Fifty Years of Pulsar\n",
    "\tCandidate Selection: From simple filters to a new principled real-time classification approach\n",
    "\tMNRAS, 2016.\n",
    "\"\"\"\n",
    "data_frame = pd.read_csv(os.path.join(here, 'HTRU_2.csv'))\n",
    "\n",
    "# .head() lets us look at the structure of the dataframe and the first 5 rows\n",
    "data_frame.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Mean of Int. Prof.  Stand. Deviation of Int. Prof.  ...  Skewness of Curve  Class\n",
       "0          102.507812                       58.882430  ...         127.393580      0\n",
       "1          103.015625                       39.341649  ...          63.171909      0\n",
       "2          136.750000                       57.178449  ...          53.593661      0\n",
       "3           88.726562                       40.672225  ...         252.567306      0\n",
       "4           93.570312                       46.698114  ...         131.394004      0\n",
       "\n",
       "[5 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean of Int. Prof.</th>\n      <th>Stand. Deviation of Int. Prof.</th>\n      <th>Excess Kurtosis of Int. Prof.</th>\n      <th>Skewness of Int. Prof.</th>\n      <th>Mean of Curve</th>\n      <th>Stand. Deviation of Curve</th>\n      <th>Excess Kurtosis of Curve</th>\n      <th>Skewness of Curve</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>102.507812</td>\n      <td>58.882430</td>\n      <td>0.465318</td>\n      <td>-0.515088</td>\n      <td>1.677258</td>\n      <td>14.860146</td>\n      <td>10.576487</td>\n      <td>127.393580</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103.015625</td>\n      <td>39.341649</td>\n      <td>0.323328</td>\n      <td>1.051164</td>\n      <td>3.121237</td>\n      <td>21.744669</td>\n      <td>7.735822</td>\n      <td>63.171909</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>136.750000</td>\n      <td>57.178449</td>\n      <td>-0.068415</td>\n      <td>-0.636238</td>\n      <td>3.642977</td>\n      <td>20.959280</td>\n      <td>6.896499</td>\n      <td>53.593661</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>88.726562</td>\n      <td>40.672225</td>\n      <td>0.600866</td>\n      <td>1.123492</td>\n      <td>1.178930</td>\n      <td>11.468720</td>\n      <td>14.269573</td>\n      <td>252.567306</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93.570312</td>\n      <td>46.698114</td>\n      <td>0.531905</td>\n      <td>0.416721</td>\n      <td>1.636288</td>\n      <td>14.545074</td>\n      <td>10.621748</td>\n      <td>131.394004</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Notice that there are no column names \n",
    "# Pandas just used the first line of data as the column headers. That's no good\n",
    "\n",
    "# We need to add meaningful headers that explain what each column is representing\n",
    "data_frame.columns =['Mean of Int. Prof.', 'Stand. Deviation of Int. Prof.', \n",
    "                     'Excess Kurtosis of Int. Prof.', 'Skewness of Int. Prof.',\n",
    "                     'Mean of Curve', ' Stand. Deviation of Curve', 'Excess Kurtosis of Curve',\n",
    "                     'Skewness of Curve', 'Class']\n",
    "\n",
    "# Now that we added column headers lets look at the header\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(17897, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# This looks much better! \n",
    "\n",
    "# Now, we need to make sure our dataset is clean so it can make a propper model\n",
    "# We need to make sure that there are no duplicates and that there is no missing data\n",
    "# Pandas has handy methods to help us check real quick\n",
    "\n",
    "# First let's make sure there are no duplicates in our data\n",
    "# Let's check the shape of the current dataframe\n",
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(17897, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# This means there are 9 columns and 17,897 Columns\n",
    "# Now let's drop all duplicate rows and see if the shape changes\n",
    "data_frame.drop_duplicates()\n",
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Mean of Int. Prof.                0\n",
       "Stand. Deviation of Int. Prof.    0\n",
       "Excess Kurtosis of Int. Prof.     0\n",
       "Skewness of Int. Prof.            0\n",
       "Mean of Curve                     0\n",
       " Stand. Deviation of Curve        0\n",
       "Excess Kurtosis of Curve          0\n",
       "Skewness of Curve                 0\n",
       "Class                             0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# Same shape, that means there were no duplicate rows in the original dataset\n",
    "# If you have a dataset with duplicates, after running drop_duplicates() \n",
    "# the dataframe will be smaller, but you can use the smaller dataframe to train your model\n",
    "\n",
    "# Now, let's check if there are any fields with missing data\n",
    "\n",
    "# the isnull() method indicates wheter or not values are missing\n",
    "# .sum() counts the number of times in the dataframe that isnull() is true\n",
    "# So basically this line of code counts the number of times there is missing data in our dataframe\n",
    "data_frame.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Non-Pulsars: 16258\nNumber of Pulsars:     1639\nRatio of Pulsars: 0.09157959434542103\n"
     ]
    }
   ],
   "source": [
    "# There is no missing data in any of the columns. YAY!\n",
    "# If you run into a dataset that does have missing data\n",
    "# you can use the pandas method .dropnull() or dropna()\n",
    "\n",
    "# Let's look at some other useful statistics on our data\n",
    "\n",
    "# Let's see how many pulsars vs non-pulsars there are in the dataframe\n",
    "\n",
    "# To break down what is done in these 2 lines\n",
    "# data_frame[data_frame.Class == 0] returns\n",
    "# a dataframe including all of the rows with a class 0\n",
    "# len simply returns the length of such a dataframe\n",
    "\n",
    "# a class of 0 is non pulsar and 1 is pulsar\n",
    "print('Number of Non-Pulsars: ' + str(len(data_frame[data_frame.Class == 0])))\n",
    "print('Number of Pulsars:     ' + str(len(data_frame[data_frame.Class == 1])))\n",
    "print('Ratio of Pulsars: ' + str(1639/(16258+1639)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(17897, 8)\n(17897, 1)\n"
     ]
    }
   ],
   "source": [
    "# There is an imbalance here. We need to be carefull that our model\n",
    "# does not bias non_pulsars too much\n",
    "# we will likely see more missed predictions of pulsars becasue of this\n",
    "\n",
    "# Since we know our dataframe is clean data, we can now start splitting it\n",
    "# up so we can start training Machine Learning Models off of it\n",
    "\n",
    "# We need to separate our dataframe into input and output\n",
    "# In our case, columns 1-8 are inputs and the output is the last column (Class)\n",
    "\n",
    "# So, we need to put the first 8 columns into a dataframe and the last one into another dataframe\n",
    "# There may be a better way to do this, but my approach was to make 2 copies of the dataframe\n",
    "# and then drop the unwanted columns\n",
    "\n",
    "# x will represent the input dataframe and y will represent the output dataframe\n",
    "\n",
    "# axis 1 represents the columns (obviously axis 0 will represent the rows)\n",
    "# inplace determines whether or not what is returned is a modified copy or \n",
    "# if the operation is done on the original dataframe\n",
    "# since we want to save a modified copy we set inplace=False\n",
    "x = data_frame.drop(['Class'], axis=1, inplace=False)\n",
    "\n",
    "# Now let's do the same thing for the outputs\n",
    "y = data_frame.drop(['Mean of Int. Prof.', 'Stand. Deviation of Int. Prof.', \n",
    "                     'Excess Kurtosis of Int. Prof.', 'Skewness of Int. Prof.',\n",
    "                     'Mean of Curve', ' Stand. Deviation of Curve', 'Excess Kurtosis of Curve',\n",
    "                     'Skewness of Curve'], axis=1, inplace=False)\n",
    "# Let's look at the shape and see if they match our expectations\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Mean of Int. Prof.  ...  Skewness of Curve\n",
       "0          102.507812  ...         127.393580\n",
       "1          103.015625  ...          63.171909\n",
       "2          136.750000  ...          53.593661\n",
       "3           88.726562  ...         252.567306\n",
       "4           93.570312  ...         131.394004\n",
       "\n",
       "[5 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean of Int. Prof.</th>\n      <th>Stand. Deviation of Int. Prof.</th>\n      <th>Excess Kurtosis of Int. Prof.</th>\n      <th>Skewness of Int. Prof.</th>\n      <th>Mean of Curve</th>\n      <th>Stand. Deviation of Curve</th>\n      <th>Excess Kurtosis of Curve</th>\n      <th>Skewness of Curve</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>102.507812</td>\n      <td>58.882430</td>\n      <td>0.465318</td>\n      <td>-0.515088</td>\n      <td>1.677258</td>\n      <td>14.860146</td>\n      <td>10.576487</td>\n      <td>127.393580</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103.015625</td>\n      <td>39.341649</td>\n      <td>0.323328</td>\n      <td>1.051164</td>\n      <td>3.121237</td>\n      <td>21.744669</td>\n      <td>7.735822</td>\n      <td>63.171909</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>136.750000</td>\n      <td>57.178449</td>\n      <td>-0.068415</td>\n      <td>-0.636238</td>\n      <td>3.642977</td>\n      <td>20.959280</td>\n      <td>6.896499</td>\n      <td>53.593661</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>88.726562</td>\n      <td>40.672225</td>\n      <td>0.600866</td>\n      <td>1.123492</td>\n      <td>1.178930</td>\n      <td>11.468720</td>\n      <td>14.269573</td>\n      <td>252.567306</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93.570312</td>\n      <td>46.698114</td>\n      <td>0.531905</td>\n      <td>0.416721</td>\n      <td>1.636288</td>\n      <td>14.545074</td>\n      <td>10.621748</td>\n      <td>131.394004</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Let's look at the heads to see what these operations did\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Class\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14317\n14317\n3580\n3580\n"
     ]
    }
   ],
   "source": [
    "# As expected now x contains all of the inputs and y contains all of the outputs\n",
    "\n",
    "# The next step is to separate our data into a training set and a testing set\n",
    "# this way we can train our model and then test it on new data it hasn't seen\n",
    "\n",
    "# sklearn has a really nice method that does this for us in 1 line\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This method returns 4 datasets 2 inputs and 2 outputs\n",
    "# The variable test_size determines what percentage of the dataframe\n",
    "# is used for test. In this case we used 20% for testing\n",
    "# which leaves 80% for training\n",
    "# random_state is just the way that it shuffles data before splitting it up\n",
    "# The documentation said 42 is common so that is the only reason I chose it\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=42)\n",
    "\n",
    "# Let's look at the size of the different dataframes to see what the function did\n",
    "print((x_train.size)//8) # divide by 8 because there are 8 columns (// is integer division in python)\n",
    "print(y_train.size)\n",
    "print((x_test.size)//8) # divide by 8 because there are 8 columns\n",
    "print(y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAINING SET STATS:\nNumber of Non-Pulsars=12999\nNumber of Pulsars=1318\nRatio of Pulsars=0.09205839212125445\n\nTESTING SET STATS:\nNumber of Non-Pulsars=3259\nNumber of Pulsars=321\nRatio of Pulsars=0.08966480446927375\n"
     ]
    }
   ],
   "source": [
    "# let's make sure the test and train sets contain a similar ratio of pulsars to non pulsars\n",
    "non_pulsar_train = len(y_train[y_train.Class == 0])\n",
    "pulsar_train = len(y_train[y_train.Class == 1])\n",
    "percent_pusar_train = pulsar_train/(non_pulsar_train+pulsar_train)\n",
    "\n",
    "non_pulsar_test = len(y_test[y_test.Class == 0])\n",
    "pulsar_test = len(y_test[y_test.Class == 1])\n",
    "percent_pusar_test = pulsar_test/(non_pulsar_test+pulsar_test)\n",
    "\n",
    "print(\"TRAINING SET STATS:\")\n",
    "print('Number of Non-Pulsars=' + str(non_pulsar_train))\n",
    "print('Number of Pulsars=' + str(pulsar_train))\n",
    "print('Ratio of Pulsars=' + str(percent_pusar_train))\n",
    "print('\\nTESTING SET STATS:')\n",
    "print('Number of Non-Pulsars=' + str(non_pulsar_test))\n",
    "print('Number of Pulsars=' + str(pulsar_test))\n",
    "print('Ratio of Pulsars=' + str(percent_pusar_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both have a good distribution very close to each other as well\n",
    "# as the overall original's distribution\n",
    "\n",
    "# Now that we have input and output can start training our models\n",
    "\n",
    "# We will use models from the scikit learn library\n",
    "# scikit learn also offers helpful metrics that will help us visualize the performance of our model\n",
    "\n",
    "# acuracy score tells us the percentage of correct predictions our model made\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Confusion matrix helps us visullize number of guesses that were right/wrong in each category\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# f1 score summarizes the accuracy of true positives/ false positives/ true negatives/ false negatives\n",
    "# basically a percentage version of the confusion matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Accuracy Score: 0.9782122905027933\n",
      "Confusion Matrix: \n",
      "[[3232   27]\n",
      " [  51  270]]\n",
      "F1 Score: [0.98807704 0.87378641]\n"
     ]
    }
   ],
   "source": [
    "# there are a ton of different modles we can use from sklearn\n",
    "# We will only focus on neural networks for this notebook\n",
    "# The process is pretty much the same for all of them, you just have to \n",
    "# reference the online documentation to see what kinds of parameters are availible to you\n",
    "\n",
    "# import the model from sklearn\n",
    "# The documentation for MLPClassifier can be found here\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# create the model with whatever parameters you want to try\n",
    "# for now I will just set the number and size of the hidden layers created\n",
    "# If you want to mess with other parameters, reference the documentation\n",
    "# This is 3 hidden layers of 10 hidden nodes each\n",
    "neural_network = MLPClassifier(hidden_layer_sizes=(10,10,10))\n",
    "\n",
    "\n",
    "# This line trains the model using the input and output of the training sets we separated before\n",
    "neural_network.fit(x_train, y_train)\n",
    "\n",
    "# This line uses the model we just created to predict the outputs of the test set\n",
    "y_predict = neural_network.predict(x_test)\n",
    "\n",
    "# now we can use the predicted outputs and the actual outputs to see how our model did\n",
    "# we will look at the performance with the sklearn metrics we imported before\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(hidden_layer_sizes=(10, 10, 10)),\n",
       "             param_grid={'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
       "                         'solver': ['lbfgs', 'sgd', 'adam']})"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "# 97% accuracy is pretty good\n",
    "\n",
    "# we can try other parameters to see if they do better\n",
    "# It is almost impossible to try all combinations by hand\n",
    "# there is a helpful method that lets us try different models \n",
    "\n",
    "# Grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Here we are comparing the 4 different values of activation and 3 different values for solver\n",
    "# Gridsearch will compare all possible combinations of these and return the best\n",
    "# The parameters are the model you want to use, a list of parameters you want to check, \n",
    "# cv and others you can look into\n",
    "# cv=5 basically splits the test data into 5 different tests and then it takes the average to rank them\n",
    "grid_search = GridSearchCV(MLPClassifier(hidden_layer_sizes=(10,10,10)),{\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam']\n",
    "}, cv=5, return_train_score=False)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "0       1.380841      0.234044  ...        0.002149                1\n",
       "1       1.472089      1.280269  ...        0.026368               11\n",
       "2       1.068559      0.420840  ...        0.003669                8\n",
       "3       2.859383      0.270557  ...        0.024955               10\n",
       "4       1.513965      1.687011  ...        0.000161               12\n",
       "\n",
       "[5 rows x 15 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_activation</th>\n      <th>param_solver</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.380841</td>\n      <td>0.234044</td>\n      <td>0.002592</td>\n      <td>0.000489</td>\n      <td>identity</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'identity', 'solver': 'lbfgs'}</td>\n      <td>0.980098</td>\n      <td>0.976955</td>\n      <td>0.980091</td>\n      <td>0.974502</td>\n      <td>0.979043</td>\n      <td>0.978138</td>\n      <td>0.002149</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.472089</td>\n      <td>1.280269</td>\n      <td>0.003067</td>\n      <td>0.000138</td>\n      <td>identity</td>\n      <td>sgd</td>\n      <td>{'activation': 'identity', 'solver': 'sgd'}</td>\n      <td>0.978003</td>\n      <td>0.967877</td>\n      <td>0.974852</td>\n      <td>0.908138</td>\n      <td>0.973454</td>\n      <td>0.960465</td>\n      <td>0.026368</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.068559</td>\n      <td>0.420840</td>\n      <td>0.002968</td>\n      <td>0.000574</td>\n      <td>identity</td>\n      <td>adam</td>\n      <td>{'activation': 'identity', 'solver': 'adam'}</td>\n      <td>0.979399</td>\n      <td>0.973813</td>\n      <td>0.972756</td>\n      <td>0.973105</td>\n      <td>0.967866</td>\n      <td>0.973388</td>\n      <td>0.003669</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.859383</td>\n      <td>0.270557</td>\n      <td>0.003969</td>\n      <td>0.000112</td>\n      <td>logistic</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'logistic', 'solver': 'lbfgs'}</td>\n      <td>0.977654</td>\n      <td>0.915154</td>\n      <td>0.976947</td>\n      <td>0.970660</td>\n      <td>0.982187</td>\n      <td>0.964520</td>\n      <td>0.024955</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.513965</td>\n      <td>1.687011</td>\n      <td>0.003262</td>\n      <td>0.000573</td>\n      <td>logistic</td>\n      <td>sgd</td>\n      <td>{'activation': 'logistic', 'solver': 'sgd'}</td>\n      <td>0.907821</td>\n      <td>0.907821</td>\n      <td>0.908138</td>\n      <td>0.908138</td>\n      <td>0.907789</td>\n      <td>0.907942</td>\n      <td>0.000161</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "# Easier to look at results if you save them to a dataframe (so we can manipulate the data with pandas mehtods)\n",
    "grid_search_results = pd.DataFrame(grid_search.cv_results_)\n",
    "grid_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "0        1.380841      0.234044  ...        0.002149                1\n",
       "6        3.210226      0.232432  ...        0.002362                2\n",
       "5        4.493720      0.859173  ...        0.003017                3\n",
       "11       1.988195      0.994426  ...        0.002220                4\n",
       "8        3.262109      0.680183  ...        0.002936                5\n",
       "\n",
       "[5 rows x 15 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_activation</th>\n      <th>param_solver</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.380841</td>\n      <td>0.234044</td>\n      <td>0.002592</td>\n      <td>0.000489</td>\n      <td>identity</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'identity', 'solver': 'lbfgs'}</td>\n      <td>0.980098</td>\n      <td>0.976955</td>\n      <td>0.980091</td>\n      <td>0.974502</td>\n      <td>0.979043</td>\n      <td>0.978138</td>\n      <td>0.002149</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3.210226</td>\n      <td>0.232432</td>\n      <td>0.004405</td>\n      <td>0.000470</td>\n      <td>tanh</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'tanh', 'solver': 'lbfgs'}</td>\n      <td>0.978352</td>\n      <td>0.974162</td>\n      <td>0.976947</td>\n      <td>0.974502</td>\n      <td>0.980440</td>\n      <td>0.976881</td>\n      <td>0.002362</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4.493720</td>\n      <td>0.859173</td>\n      <td>0.003664</td>\n      <td>0.000376</td>\n      <td>logistic</td>\n      <td>adam</td>\n      <td>{'activation': 'logistic', 'solver': 'adam'}</td>\n      <td>0.980447</td>\n      <td>0.973115</td>\n      <td>0.979392</td>\n      <td>0.973454</td>\n      <td>0.977646</td>\n      <td>0.976811</td>\n      <td>0.003017</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.988195</td>\n      <td>0.994426</td>\n      <td>0.002858</td>\n      <td>0.000461</td>\n      <td>relu</td>\n      <td>adam</td>\n      <td>{'activation': 'relu', 'solver': 'adam'}</td>\n      <td>0.979050</td>\n      <td>0.972416</td>\n      <td>0.974153</td>\n      <td>0.974502</td>\n      <td>0.975899</td>\n      <td>0.975204</td>\n      <td>0.002220</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3.262109</td>\n      <td>0.680183</td>\n      <td>0.004001</td>\n      <td>0.000028</td>\n      <td>tanh</td>\n      <td>adam</td>\n      <td>{'activation': 'tanh', 'solver': 'adam'}</td>\n      <td>0.979749</td>\n      <td>0.971020</td>\n      <td>0.974852</td>\n      <td>0.975201</td>\n      <td>0.972756</td>\n      <td>0.974715</td>\n      <td>0.002936</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "# this gives us a bunch of helpful data\n",
    "# We can sort based on the rank of the different tests so it is in order of best to worst combinations\n",
    "# by tells us which column value we want to sort by\n",
    "# axis tells us which we are sorting (we want to sort the rows)\n",
    "# ascending is self explanitory\n",
    "grid_search_results = grid_search_results.sort_values(by=['rank_test_score'], axis=0, ascending=True)\n",
    "grid_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you wanted to save this dataframe use the following\n",
    "# you could use this to do further study on the results\n",
    "grid_search_results.to_csv('tutorialGridSearch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last thing I want to look at in this tutorial is the library pickle\n",
    "# This allows you to save trained models to your hard drive\n",
    "# you can use this to save the best models that could be used for further use\n",
    "import pickle\n",
    "\n",
    "# this is just creating a file to write to and dumping the pickle\n",
    "with open(os.path.join(here, 'tutorialGridsearch.pkl'), 'wb') as f:\n",
    "    pickle.dump(neural_network, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load a pickle do the following\n",
    "with open(os.path.join(here, 'tutorialGridsearch.pkl'), 'rb') as f:\n",
    "    pickled_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9782122905027933"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "# so directly from loading we can use it to predict again\n",
    "y_predict = pickled_model.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
