{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         140.5625  55.68378214  -0.234571412  -0.699648398  3.199832776  \\\n",
       "0      102.507812    58.882430      0.465318     -0.515088     1.677258   \n",
       "1      103.015625    39.341649      0.323328      1.051164     3.121237   \n",
       "2      136.750000    57.178449     -0.068415     -0.636238     3.642977   \n",
       "3       88.726562    40.672225      0.600866      1.123492     1.178930   \n",
       "4       93.570312    46.698114      0.531905      0.416721     1.636288   \n",
       "...           ...          ...           ...           ...          ...   \n",
       "17892  136.429688    59.847421     -0.187846     -0.738123     1.296823   \n",
       "17893  122.554688    49.485605      0.127978      0.323061    16.409699   \n",
       "17894  119.335938    59.935939      0.159363     -0.743025    21.430602   \n",
       "17895  114.507812    53.902400      0.201161     -0.024789     1.946488   \n",
       "17896   57.062500    85.797340      1.406391      0.089520   188.306020   \n",
       "\n",
       "       19.11042633  7.975531794  74.24222492  0  \n",
       "0        14.860146    10.576487   127.393580  0  \n",
       "1        21.744669     7.735822    63.171909  0  \n",
       "2        20.959280     6.896499    53.593661  0  \n",
       "3        11.468720    14.269573   252.567306  0  \n",
       "4        14.545074    10.621748   131.394004  0  \n",
       "...            ...          ...          ... ..  \n",
       "17892    12.166062    15.450260   285.931022  0  \n",
       "17893    44.626893     2.945244     8.297092  0  \n",
       "17894    58.872000     2.499517     4.595173  0  \n",
       "17895    13.381731    10.007967   134.238910  0  \n",
       "17896    64.712562    -1.597527     1.429475  0  \n",
       "\n",
       "[17897 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>140.5625</th>\n      <th>55.68378214</th>\n      <th>-0.234571412</th>\n      <th>-0.699648398</th>\n      <th>3.199832776</th>\n      <th>19.11042633</th>\n      <th>7.975531794</th>\n      <th>74.24222492</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>102.507812</td>\n      <td>58.882430</td>\n      <td>0.465318</td>\n      <td>-0.515088</td>\n      <td>1.677258</td>\n      <td>14.860146</td>\n      <td>10.576487</td>\n      <td>127.393580</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103.015625</td>\n      <td>39.341649</td>\n      <td>0.323328</td>\n      <td>1.051164</td>\n      <td>3.121237</td>\n      <td>21.744669</td>\n      <td>7.735822</td>\n      <td>63.171909</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>136.750000</td>\n      <td>57.178449</td>\n      <td>-0.068415</td>\n      <td>-0.636238</td>\n      <td>3.642977</td>\n      <td>20.959280</td>\n      <td>6.896499</td>\n      <td>53.593661</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>88.726562</td>\n      <td>40.672225</td>\n      <td>0.600866</td>\n      <td>1.123492</td>\n      <td>1.178930</td>\n      <td>11.468720</td>\n      <td>14.269573</td>\n      <td>252.567306</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93.570312</td>\n      <td>46.698114</td>\n      <td>0.531905</td>\n      <td>0.416721</td>\n      <td>1.636288</td>\n      <td>14.545074</td>\n      <td>10.621748</td>\n      <td>131.394004</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17892</th>\n      <td>136.429688</td>\n      <td>59.847421</td>\n      <td>-0.187846</td>\n      <td>-0.738123</td>\n      <td>1.296823</td>\n      <td>12.166062</td>\n      <td>15.450260</td>\n      <td>285.931022</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17893</th>\n      <td>122.554688</td>\n      <td>49.485605</td>\n      <td>0.127978</td>\n      <td>0.323061</td>\n      <td>16.409699</td>\n      <td>44.626893</td>\n      <td>2.945244</td>\n      <td>8.297092</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17894</th>\n      <td>119.335938</td>\n      <td>59.935939</td>\n      <td>0.159363</td>\n      <td>-0.743025</td>\n      <td>21.430602</td>\n      <td>58.872000</td>\n      <td>2.499517</td>\n      <td>4.595173</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17895</th>\n      <td>114.507812</td>\n      <td>53.902400</td>\n      <td>0.201161</td>\n      <td>-0.024789</td>\n      <td>1.946488</td>\n      <td>13.381731</td>\n      <td>10.007967</td>\n      <td>134.238910</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17896</th>\n      <td>57.062500</td>\n      <td>85.797340</td>\n      <td>1.406391</td>\n      <td>0.089520</td>\n      <td>188.306020</td>\n      <td>64.712562</td>\n      <td>-1.597527</td>\n      <td>1.429475</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>17897 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "# this is another attempt at messing with the pulsar data\n",
    "# after going thorugh the sklearn tutorial and the pandas tutorial\n",
    "\n",
    "# This gets your current working directory for some of the methods\n",
    "# I added this because I was having some trouble with the pickles\n",
    "here = os.getcwd()\n",
    "\n",
    "import pandas as pd\n",
    "data_frame = pd.read_csv(os.path.join(here, 'HTRU_2.csv'))\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Mean of Int. Prof.  Stand. Deviation of Int. Prof.  \\\n",
       "0              102.507812                       58.882430   \n",
       "1              103.015625                       39.341649   \n",
       "2              136.750000                       57.178449   \n",
       "3               88.726562                       40.672225   \n",
       "4               93.570312                       46.698114   \n",
       "...                   ...                             ...   \n",
       "17892          136.429688                       59.847421   \n",
       "17893          122.554688                       49.485605   \n",
       "17894          119.335938                       59.935939   \n",
       "17895          114.507812                       53.902400   \n",
       "17896           57.062500                       85.797340   \n",
       "\n",
       "       Excess Kurtosis of Int. Prof.  Skewness of Int. Prof.  Mean of Curve  \\\n",
       "0                           0.465318               -0.515088       1.677258   \n",
       "1                           0.323328                1.051164       3.121237   \n",
       "2                          -0.068415               -0.636238       3.642977   \n",
       "3                           0.600866                1.123492       1.178930   \n",
       "4                           0.531905                0.416721       1.636288   \n",
       "...                              ...                     ...            ...   \n",
       "17892                      -0.187846               -0.738123       1.296823   \n",
       "17893                       0.127978                0.323061      16.409699   \n",
       "17894                       0.159363               -0.743025      21.430602   \n",
       "17895                       0.201161               -0.024789       1.946488   \n",
       "17896                       1.406391                0.089520     188.306020   \n",
       "\n",
       "        Stand. Deviation of Curve  Excess Kurtosis of Curve  \\\n",
       "0                       14.860146                 10.576487   \n",
       "1                       21.744669                  7.735822   \n",
       "2                       20.959280                  6.896499   \n",
       "3                       11.468720                 14.269573   \n",
       "4                       14.545074                 10.621748   \n",
       "...                           ...                       ...   \n",
       "17892                   12.166062                 15.450260   \n",
       "17893                   44.626893                  2.945244   \n",
       "17894                   58.872000                  2.499517   \n",
       "17895                   13.381731                 10.007967   \n",
       "17896                   64.712562                 -1.597527   \n",
       "\n",
       "       Skewness of Curve  Class  \n",
       "0             127.393580      0  \n",
       "1              63.171909      0  \n",
       "2              53.593661      0  \n",
       "3             252.567306      0  \n",
       "4             131.394004      0  \n",
       "...                  ...    ...  \n",
       "17892         285.931022      0  \n",
       "17893           8.297092      0  \n",
       "17894           4.595173      0  \n",
       "17895         134.238910      0  \n",
       "17896           1.429475      0  \n",
       "\n",
       "[17897 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean of Int. Prof.</th>\n      <th>Stand. Deviation of Int. Prof.</th>\n      <th>Excess Kurtosis of Int. Prof.</th>\n      <th>Skewness of Int. Prof.</th>\n      <th>Mean of Curve</th>\n      <th>Stand. Deviation of Curve</th>\n      <th>Excess Kurtosis of Curve</th>\n      <th>Skewness of Curve</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>102.507812</td>\n      <td>58.882430</td>\n      <td>0.465318</td>\n      <td>-0.515088</td>\n      <td>1.677258</td>\n      <td>14.860146</td>\n      <td>10.576487</td>\n      <td>127.393580</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103.015625</td>\n      <td>39.341649</td>\n      <td>0.323328</td>\n      <td>1.051164</td>\n      <td>3.121237</td>\n      <td>21.744669</td>\n      <td>7.735822</td>\n      <td>63.171909</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>136.750000</td>\n      <td>57.178449</td>\n      <td>-0.068415</td>\n      <td>-0.636238</td>\n      <td>3.642977</td>\n      <td>20.959280</td>\n      <td>6.896499</td>\n      <td>53.593661</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>88.726562</td>\n      <td>40.672225</td>\n      <td>0.600866</td>\n      <td>1.123492</td>\n      <td>1.178930</td>\n      <td>11.468720</td>\n      <td>14.269573</td>\n      <td>252.567306</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93.570312</td>\n      <td>46.698114</td>\n      <td>0.531905</td>\n      <td>0.416721</td>\n      <td>1.636288</td>\n      <td>14.545074</td>\n      <td>10.621748</td>\n      <td>131.394004</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17892</th>\n      <td>136.429688</td>\n      <td>59.847421</td>\n      <td>-0.187846</td>\n      <td>-0.738123</td>\n      <td>1.296823</td>\n      <td>12.166062</td>\n      <td>15.450260</td>\n      <td>285.931022</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17893</th>\n      <td>122.554688</td>\n      <td>49.485605</td>\n      <td>0.127978</td>\n      <td>0.323061</td>\n      <td>16.409699</td>\n      <td>44.626893</td>\n      <td>2.945244</td>\n      <td>8.297092</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17894</th>\n      <td>119.335938</td>\n      <td>59.935939</td>\n      <td>0.159363</td>\n      <td>-0.743025</td>\n      <td>21.430602</td>\n      <td>58.872000</td>\n      <td>2.499517</td>\n      <td>4.595173</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17895</th>\n      <td>114.507812</td>\n      <td>53.902400</td>\n      <td>0.201161</td>\n      <td>-0.024789</td>\n      <td>1.946488</td>\n      <td>13.381731</td>\n      <td>10.007967</td>\n      <td>134.238910</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17896</th>\n      <td>57.062500</td>\n      <td>85.797340</td>\n      <td>1.406391</td>\n      <td>0.089520</td>\n      <td>188.306020</td>\n      <td>64.712562</td>\n      <td>-1.597527</td>\n      <td>1.429475</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>17897 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "# need to add column names\n",
    "data_frame.columns =['Mean of Int. Prof.', 'Stand. Deviation of Int. Prof.', \n",
    "                     'Excess Kurtosis of Int. Prof.', 'Skewness of Int. Prof.',\n",
    "                     'Mean of Curve', ' Stand. Deviation of Curve', 'Excess Kurtosis of Curve',\n",
    "                     'Skewness of Curve', 'Class']\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(17897, 8)\n(17897, 1)\n13014\n1303\n"
     ]
    }
   ],
   "source": [
    "# I already know from previous scannings of this dataset that it is fairly clean\n",
    "# I want to use some prewritten algorithms from sklearn to see which general algorithm will work better\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data_frame.copy()\n",
    "x.drop(['Class'], axis=1, inplace=True)\n",
    "y = data_frame.copy()\n",
    "y.drop(['Mean of Int. Prof.', 'Stand. Deviation of Int. Prof.', \n",
    "                     'Excess Kurtosis of Int. Prof.', 'Skewness of Int. Prof.',\n",
    "                     'Mean of Curve', ' Stand. Deviation of Curve', 'Excess Kurtosis of Curve',\n",
    "                     'Skewness of Curve'], axis=1, inplace=True)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=.2, random_state=1)\n",
    "\n",
    "print(len(y_train[y_train.Class == 0]))\n",
    "print(len(y_train[y_train.Class == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14317, 9)\n(13014, 9)\n(1303, 9)\n(1303, 9)\n(2606, 9)\n(2606, 8)\n(2606, 1)\n"
     ]
    }
   ],
   "source": [
    "# obviously not evenly distributed, I want to test out training on both evenly distributed and this distribution\n",
    "\n",
    "train_data = x_train.copy()\n",
    "train_data['Class'] = y_train\n",
    "print(train_data.shape)\n",
    "\n",
    "train_data_non_pulsar = train_data[train_data['Class'] == 0]\n",
    "train_data_pulsar = train_data[train_data['Class'] == 1]\n",
    "\n",
    "print(train_data_non_pulsar.shape) # this matches YAY\n",
    "print(train_data_pulsar.shape)\n",
    "\n",
    "#shuffle the non pulsar data\n",
    "from sklearn.utils import shuffle\n",
    "train_data_non_pulsar = shuffle(train_data_non_pulsar)\n",
    "\n",
    "#cut to same size as pulsar data\n",
    "train_data_non_pulsar = train_data_non_pulsar[:1303]\n",
    "print(train_data_non_pulsar.shape)\n",
    "\n",
    "train_data_balanced = train_data_non_pulsar.append(train_data_pulsar)\n",
    "train_data_balanced = shuffle(train_data_balanced)\n",
    "print(train_data_balanced.shape)\n",
    "train_data_balanced[:10]\n",
    "\n",
    "x_train_balanced = train_data_balanced.copy()\n",
    "x_train_balanced.drop(['Class'], axis=1, inplace=True)\n",
    "y_train_balanced = train_data_balanced.copy()\n",
    "y_train_balanced.drop(['Mean of Int. Prof.', 'Stand. Deviation of Int. Prof.', \n",
    "                     'Excess Kurtosis of Int. Prof.', 'Skewness of Int. Prof.',\n",
    "                     'Mean of Curve', ' Stand. Deviation of Curve', 'Excess Kurtosis of Curve',\n",
    "                     'Skewness of Curve'], axis=1, inplace=True)\n",
    "\n",
    "print(x_train_balanced.shape)\n",
    "print(y_train_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Unbalanced: \n",
      "Accuracy Score: 0.9756983240223464\n",
      "Confusion Matrix: \n",
      "[[3224   20]\n",
      " [  67  269]]\n",
      "F1 Score: [0.98668707 0.8608    ]\n",
      "Balanced:\n",
      "Accuracy Score: 0.9681564245810056\n",
      "Confusion Matrix: \n",
      "[[3160   84]\n",
      " [  30  306]]\n",
      "F1 Score: [0.98228163 0.84297521]\n"
     ]
    }
   ],
   "source": [
    "# now we can train ( will train on both balanced and unbalanced but test on same test group )\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "logistic_regression.fit(x_train, y_train)\n",
    "y_predict = logistic_regression.predict(x_test)\n",
    "\n",
    "print(\"Unbalanced: \")\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))\n",
    "\n",
    "print(\"Balanced:\")\n",
    "logistic_regression.fit(x_train_balanced, y_train_balanced)\n",
    "y_predict = logistic_regression.predict(x_test)\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unbalanced: \n",
      "Accuracy Score: 0.7656424581005586\n",
      "Confusion Matrix: \n",
      "[[2738  506]\n",
      " [ 333    3]]\n",
      "F1 Score: [0.86714173 0.00710059]\n",
      "Balanced:\n",
      "Accuracy Score: 0.4047486033519553\n",
      "Confusion Matrix: \n",
      "[[1437 1807]\n",
      " [ 324   12]]\n",
      "F1 Score: [0.57422577 0.01113689]\n"
     ]
    }
   ],
   "source": [
    "# K Means clustering.... This was very bad\n",
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters=2, random_state=0)\n",
    "\n",
    "k_means.fit(x_train, y_train)\n",
    "y_predict = k_means.predict(x_test)\n",
    "\n",
    "print(\"Unbalanced: \")\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))\n",
    "\n",
    "print(\"Balanced:\")\n",
    "k_means.fit(x_train_balanced, y_train_balanced)\n",
    "y_predict = k_means.predict(x_test)\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unbalanced: \n",
      "Accuracy Score: 0.9650837988826816\n",
      "Confusion Matrix: \n",
      "[[3183   61]\n",
      " [  64  272]]\n",
      "F1 Score: [0.98074257 0.81315396]\n",
      "Balanced:\n",
      "Accuracy Score: 0.9069832402234637\n",
      "Confusion Matrix: \n",
      "[[2944  300]\n",
      " [  33  303]]\n",
      "F1 Score: [0.94647163 0.64536741]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_predict = decision_tree.predict(x_test)\n",
    "\n",
    "print(\"Unbalanced: \")\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))\n",
    "\n",
    "print(\"Balanced:\")\n",
    "decision_tree.fit(x_train_balanced, y_train_balanced)\n",
    "y_predict = decision_tree.predict(x_test)\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Unbalanced: \n",
      "Accuracy Score: 0.9069832402234637\n",
      "Confusion Matrix: \n",
      "[[3243    1]\n",
      " [ 332    4]]\n",
      "F1 Score: [0.95116586 0.02346041]\n",
      "Balanced:\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Accuracy Score: 0.6293296089385475\n",
      "Confusion Matrix: \n",
      "[[1934 1310]\n",
      " [  17  319]]\n",
      "F1 Score: [0.74456208 0.32468193]\n"
     ]
    }
   ],
   "source": [
    "# SVC not great either\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(gamma='auto')\n",
    "\n",
    "svc.fit(x_train, y_train)\n",
    "y_predict = svc.predict(x_test)\n",
    "\n",
    "print(\"Unbalanced: \")\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))\n",
    "\n",
    "print(\"Balanced:\")\n",
    "svc.fit(x_train_balanced, y_train_balanced)\n",
    "y_predict = svc.predict(x_test)\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Unbalanced: \n",
      "Accuracy Score: 0.9712290502793296\n",
      "Confusion Matrix: \n",
      "[[3221   23]\n",
      " [  80  256]]\n",
      "F1 Score: [0.9842628  0.83252033]\n",
      "Balanced:\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Accuracy Score: 0.9513966480446927\n",
      "Confusion Matrix: \n",
      "[[3108  136]\n",
      " [  38  298]]\n",
      "F1 Score: [0.97276995 0.77402597]\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "neural_network = MLPClassifier(hidden_layer_sizes=(10,10,10))\n",
    "\n",
    "neural_network.fit(x_train, y_train)\n",
    "y_predict = neural_network.predict(x_test)\n",
    "\n",
    "print(\"Unbalanced: \")\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))\n",
    "\n",
    "print(\"Balanced:\")\n",
    "neural_network.fit(x_train_balanced, y_train_balanced)\n",
    "y_predict = neural_network.predict(x_test)\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ultilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       ",\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'activation': 'identity',\n",
       "   'hidden_layer_sizes': 10,\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity', 'hidden_layer_sizes': 10, 'solver': 'sgd'},\n",
       "  {'activation': 'identity', 'hidden_layer_sizes': 10, 'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (10, 10),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity', 'hidden_layer_sizes': (10, 10), 'solver': 'sgd'},\n",
       "  {'activation': 'identity', 'hidden_layer_sizes': (10, 10), 'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (10, 10, 10),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (10, 10, 10),\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (10, 10, 10),\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (10, 10, 10, 10),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (10, 10, 10, 10),\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (10, 10, 10, 10),\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity', 'hidden_layer_sizes': 5, 'solver': 'lbfgs'},\n",
       "  {'activation': 'identity', 'hidden_layer_sizes': 5, 'solver': 'sgd'},\n",
       "  {'activation': 'identity', 'hidden_layer_sizes': 5, 'solver': 'adam'},\n",
       "  {'activation': 'identity', 'hidden_layer_sizes': (5, 5), 'solver': 'lbfgs'},\n",
       "  {'activation': 'identity', 'hidden_layer_sizes': (5, 5), 'solver': 'sgd'},\n",
       "  {'activation': 'identity', 'hidden_layer_sizes': (5, 5), 'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (5, 5, 5),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity', 'hidden_layer_sizes': (5, 5, 5), 'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (5, 5, 5),\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (5, 5, 5, 5),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (5, 5, 5, 5),\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (5, 5, 5, 5),\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (5, 10, 5),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (5, 10, 5),\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'identity',\n",
       "   'hidden_layer_sizes': (5, 10, 5),\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic', 'hidden_layer_sizes': 10, 'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic', 'hidden_layer_sizes': 10, 'solver': 'sgd'},\n",
       "  {'activation': 'logistic', 'hidden_layer_sizes': 10, 'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (10, 10),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic', 'hidden_layer_sizes': (10, 10), 'solver': 'sgd'},\n",
       "  {'activation': 'logistic', 'hidden_layer_sizes': (10, 10), 'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (10, 10, 10),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (10, 10, 10),\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (10, 10, 10),\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (10, 10, 10, 10),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (10, 10, 10, 10),\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (10, 10, 10, 10),\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic', 'hidden_layer_sizes': 5, 'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic', 'hidden_layer_sizes': 5, 'solver': 'sgd'},\n",
       "  {'activation': 'logistic', 'hidden_layer_sizes': 5, 'solver': 'adam'},\n",
       "  {'activation': 'logistic', 'hidden_layer_sizes': (5, 5), 'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic', 'hidden_layer_sizes': (5, 5), 'solver': 'sgd'},\n",
       "  {'activation': 'logistic', 'hidden_layer_sizes': (5, 5), 'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (5, 5, 5),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic', 'hidden_layer_sizes': (5, 5, 5), 'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (5, 5, 5),\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (5, 5, 5, 5),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (5, 5, 5, 5),\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (5, 5, 5, 5),\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (5, 10, 5),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (5, 10, 5),\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (5, 10, 5),\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': 10, 'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': 10, 'solver': 'sgd'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': 10, 'solver': 'adam'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (10, 10), 'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (10, 10), 'solver': 'sgd'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (10, 10), 'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (10, 10, 10),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'sgd'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (10, 10, 10, 10),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (10, 10, 10, 10),\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (10, 10, 10, 10),\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': 5, 'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': 5, 'solver': 'sgd'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': 5, 'solver': 'adam'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (5, 5), 'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (5, 5), 'solver': 'sgd'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (5, 5), 'solver': 'adam'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (5, 5, 5), 'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (5, 5, 5), 'solver': 'sgd'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (5, 5, 5), 'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (5, 5, 5, 5),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (5, 5, 5, 5), 'solver': 'sgd'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (5, 5, 5, 5), 'solver': 'adam'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (5, 10, 5), 'solver': 'lbfgs'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (5, 10, 5), 'solver': 'sgd'},\n",
       "  {'activation': 'tanh', 'hidden_layer_sizes': (5, 10, 5), 'solver': 'adam'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': 10, 'solver': 'lbfgs'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': 10, 'solver': 'sgd'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': 10, 'solver': 'adam'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (10, 10), 'solver': 'lbfgs'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (10, 10), 'solver': 'sgd'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (10, 10), 'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (10, 10, 10),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'sgd'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (10, 10, 10, 10),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (10, 10, 10, 10),\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (10, 10, 10, 10),\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': 5, 'solver': 'lbfgs'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': 5, 'solver': 'sgd'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': 5, 'solver': 'adam'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (5, 5), 'solver': 'lbfgs'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (5, 5), 'solver': 'sgd'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (5, 5), 'solver': 'adam'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (5, 5, 5), 'solver': 'lbfgs'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (5, 5, 5), 'solver': 'sgd'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (5, 5, 5), 'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (5, 5, 5, 5),\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (5, 5, 5, 5), 'solver': 'sgd'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (5, 5, 5, 5), 'solver': 'adam'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (5, 10, 5), 'solver': 'lbfgs'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (5, 10, 5), 'solver': 'sgd'},\n",
       "  {'activation': 'relu', 'hidden_layer_sizes': (5, 10, 5), 'solver': 'adam'}],\n",
       " 'split0_test_score': array([0.98184358, 0.97765363, 0.97800279, 0.98149441, 0.97660615,\n",
       "        0.97625698, 0.98044693, 0.97800279, 0.97800279, 0.98149441,\n",
       "        0.90886872, 0.97625698, 0.98149441, 0.97660615, 0.97695531,\n",
       "        0.98079609, 0.97660615, 0.97625698, 0.98114525, 0.97660615,\n",
       "        0.97870112, 0.97870112, 0.97765363, 0.97765363, 0.98079609,\n",
       "        0.97695531, 0.9752095 , 0.97590782, 0.97800279, 0.97625698,\n",
       "        0.97695531, 0.97625698, 0.97730447, 0.9797486 , 0.90886872,\n",
       "        0.97730447, 0.97905028, 0.90886872, 0.97870112, 0.97660615,\n",
       "        0.97730447, 0.97905028, 0.97835196, 0.90886872, 0.97835196,\n",
       "        0.95740223, 0.90886872, 0.97800279, 0.93610335, 0.90886872,\n",
       "        0.9797486 , 0.97905028, 0.90886872, 0.97695531, 0.97765363,\n",
       "        0.97695531, 0.97870112, 0.97905028, 0.97695531, 0.97695531,\n",
       "        0.97451117, 0.97381285, 0.97590782, 0.97870112, 0.97660615,\n",
       "        0.98149441, 0.9752095 , 0.97171788, 0.97730447, 0.97660615,\n",
       "        0.97765363, 0.97905028, 0.97486034, 0.97276536, 0.97939944,\n",
       "        0.97625698, 0.97590782, 0.97625698, 0.97800279, 0.97311453,\n",
       "        0.98149441, 0.97765363, 0.97905028, 0.97905028, 0.97835196,\n",
       "        0.97730447, 0.97870112, 0.9797486 , 0.97590782, 0.97800279,\n",
       "        0.97870112, 0.97625698, 0.97939944, 0.97625698, 0.97835196,\n",
       "        0.97730447, 0.90886872, 0.97765363, 0.97905028, 0.97730447,\n",
       "        0.97660615, 0.97870112, 0.97765363, 0.97870112, 0.98009777,\n",
       "        0.97765363, 0.97660615, 0.97905028]),\n",
       " 'split1_test_score': array([0.97660615, 0.97381285, 0.97486034, 0.97625698, 0.97381285,\n",
       "        0.9724162 , 0.97695531, 0.90886872, 0.97346369, 0.97660615,\n",
       "        0.90886872, 0.97486034, 0.97730447, 0.9724162 , 0.97486034,\n",
       "        0.97730447, 0.97451117, 0.97416201, 0.97625698, 0.97311453,\n",
       "        0.97171788, 0.97590782, 0.97311453, 0.97311453, 0.97695531,\n",
       "        0.97276536, 0.96613128, 0.9752095 , 0.9752095 , 0.97451117,\n",
       "        0.97311453, 0.90886872, 0.97381285, 0.97486034, 0.90886872,\n",
       "        0.97486034, 0.97416201, 0.90886872, 0.9752095 , 0.9724162 ,\n",
       "        0.97276536, 0.97625698, 0.97346369, 0.90886872, 0.97451117,\n",
       "        0.96962291, 0.90886872, 0.97590782, 0.97381285, 0.90886872,\n",
       "        0.97486034, 0.9521648 , 0.90886872, 0.97486034, 0.97660615,\n",
       "        0.97171788, 0.97590782, 0.97311453, 0.97171788, 0.9752095 ,\n",
       "        0.97381285, 0.97101955, 0.97486034, 0.97555866, 0.97416201,\n",
       "        0.97486034, 0.97451117, 0.97381285, 0.97486034, 0.97346369,\n",
       "        0.97311453, 0.97381285, 0.97451117, 0.97311453, 0.97206704,\n",
       "        0.9752095 , 0.97416201, 0.97346369, 0.9724162 , 0.97346369,\n",
       "        0.97486034, 0.97276536, 0.97381285, 0.97451117, 0.97346369,\n",
       "        0.97346369, 0.97451117, 0.97381285, 0.97416201, 0.97416201,\n",
       "        0.97486034, 0.97416201, 0.97555866, 0.9752095 , 0.96787709,\n",
       "        0.97590782, 0.97381285, 0.96997207, 0.97451117, 0.97416201,\n",
       "        0.97067039, 0.97381285, 0.97451117, 0.97067039, 0.97416201,\n",
       "        0.97416201, 0.9724162 , 0.97590782]),\n",
       " 'split2_test_score': array([0.98009081, 0.97485155, 0.97834439, 0.98113867, 0.97764583,\n",
       "        0.97904296, 0.90918617, 0.97520084, 0.97694726, 0.97869368,\n",
       "        0.90918617, 0.97589941, 0.98148795, 0.97520084, 0.97624869,\n",
       "        0.98148795, 0.97624869, 0.97904296, 0.98148795, 0.97415299,\n",
       "        0.97729654, 0.98148795, 0.97624869, 0.97694726, 0.98113867,\n",
       "        0.97659797, 0.97555012, 0.97764583, 0.97729654, 0.97869368,\n",
       "        0.97729654, 0.97485155, 0.97694726, 0.97031086, 0.90918617,\n",
       "        0.97764583, 0.97589941, 0.90918617, 0.98009081, 0.97834439,\n",
       "        0.97694726, 0.97869368, 0.97694726, 0.90918617, 0.97834439,\n",
       "        0.97589941, 0.90918617, 0.97939225, 0.90918617, 0.90918617,\n",
       "        0.97764583, 0.97205728, 0.90918617, 0.97939225, 0.97694726,\n",
       "        0.97485155, 0.97939225, 0.97694726, 0.97205728, 0.98078938,\n",
       "        0.97729654, 0.97659797, 0.97764583, 0.97624869, 0.97205728,\n",
       "        0.98113867, 0.97799511, 0.971708  , 0.97694726, 0.97520084,\n",
       "        0.97135871, 0.97415299, 0.96472232, 0.97310513, 0.98183723,\n",
       "        0.94935382, 0.97520084, 0.98113867, 0.97659797, 0.97345442,\n",
       "        0.97520084, 0.97869368, 0.97659797, 0.97869368, 0.97729654,\n",
       "        0.97659797, 0.97834439, 0.97694726, 0.97694726, 0.97939225,\n",
       "        0.97694726, 0.97659797, 0.97904296, 0.97939225, 0.97589941,\n",
       "        0.97659797, 0.90918617, 0.97764583, 0.97729654, 0.97589941,\n",
       "        0.97589941, 0.97624869, 0.90918617, 0.97624869, 0.97694726,\n",
       "        0.97694726, 0.97415299, 0.97834439]),\n",
       " 'split3_test_score': array([0.98009081, 0.97799511, 0.97869368, 0.9804401 , 0.97694726,\n",
       "        0.97904296, 0.97939225, 0.97485155, 0.97904296, 0.9804401 ,\n",
       "        0.97694726, 0.97834439, 0.98078938, 0.97939225, 0.97904296,\n",
       "        0.98148795, 0.97450227, 0.97939225, 0.98078938, 0.97869368,\n",
       "        0.97904296, 0.98148795, 0.97764583, 0.97904296, 0.97974153,\n",
       "        0.97275585, 0.97904296, 0.97729654, 0.97624869, 0.97834439,\n",
       "        0.97589941, 0.97310513, 0.97904296, 0.97520084, 0.90918617,\n",
       "        0.97659797, 0.97869368, 0.90918617, 0.97764583, 0.97939225,\n",
       "        0.97729654, 0.97974153, 0.97904296, 0.97589941, 0.97764583,\n",
       "        0.97415299, 0.90918617, 0.97834439, 0.9738037 , 0.90918617,\n",
       "        0.97729654, 0.97485155, 0.90918617, 0.97799511, 0.97694726,\n",
       "        0.97520084, 0.98183723, 0.97624869, 0.97589941, 0.97904296,\n",
       "        0.97834439, 0.97694726, 0.97520084, 0.9804401 , 0.97869368,\n",
       "        0.97869368, 0.97485155, 0.97729654, 0.97659797, 0.97485155,\n",
       "        0.97589941, 0.97764583, 0.97520084, 0.97415299, 0.98218652,\n",
       "        0.98183723, 0.97066015, 0.97869368, 0.97974153, 0.97275585,\n",
       "        0.97974153, 0.97904296, 0.97555012, 0.97904296, 0.97869368,\n",
       "        0.97694726, 0.97694726, 0.97589941, 0.97555012, 0.97764583,\n",
       "        0.97729654, 0.97694726, 0.97834439, 0.97834439, 0.97869368,\n",
       "        0.97939225, 0.97589941, 0.97694726, 0.97520084, 0.97834439,\n",
       "        0.97659797, 0.97694726, 0.97589941, 0.97764583, 0.97834439,\n",
       "        0.97799511, 0.97589941, 0.97764583]),\n",
       " 'split4_test_score': array([0.97834439, 0.97415299, 0.97589941, 0.97834439, 0.9738037 ,\n",
       "        0.97589941, 0.97799511, 0.97345442, 0.97520084, 0.97764583,\n",
       "        0.90883688, 0.97624869, 0.97799511, 0.97310513, 0.97694726,\n",
       "        0.97799511, 0.97345442, 0.9738037 , 0.97624869, 0.97275585,\n",
       "        0.97555012, 0.97450227, 0.97135871, 0.97310513, 0.97834439,\n",
       "        0.96996158, 0.97415299, 0.97624869, 0.97589941, 0.97624869,\n",
       "        0.9738037 , 0.97240657, 0.97589941, 0.971708  , 0.90883688,\n",
       "        0.97520084, 0.97555012, 0.90883688, 0.97694726, 0.97729654,\n",
       "        0.97589941, 0.97589941, 0.96402375, 0.90883688, 0.9738037 ,\n",
       "        0.97275585, 0.90883688, 0.97659797, 0.97624869, 0.90883688,\n",
       "        0.97520084, 0.97834439, 0.90883688, 0.97589941, 0.97694726,\n",
       "        0.97485155, 0.97520084, 0.9738037 , 0.97135871, 0.97415299,\n",
       "        0.97589941, 0.96786587, 0.97555012, 0.97834439, 0.97310513,\n",
       "        0.9738037 , 0.97310513, 0.96542089, 0.97589941, 0.97624869,\n",
       "        0.97310513, 0.97555012, 0.97589941, 0.9738037 , 0.97450227,\n",
       "        0.97834439, 0.91791827, 0.97485155, 0.97659797, 0.97310513,\n",
       "        0.97764583, 0.97520084, 0.97485155, 0.97694726, 0.90883688,\n",
       "        0.971708  , 0.97555012, 0.97520084, 0.97450227, 0.97520084,\n",
       "        0.97589941, 0.97450227, 0.97589941, 0.97135871, 0.97485155,\n",
       "        0.97555012, 0.97205728, 0.97240657, 0.9738037 , 0.97310513,\n",
       "        0.97100943, 0.97729654, 0.97345442, 0.9738037 , 0.97624869,\n",
       "        0.97555012, 0.971708  , 0.97415299]),\n",
       " 'mean_test_score': array([0.97939515, 0.97569323, 0.97716012, 0.97953491, 0.97576316,\n",
       "        0.9765317 , 0.96479515, 0.96207566, 0.97653151, 0.97897603,\n",
       "        0.92254155, 0.97632196, 0.97981426, 0.97534411, 0.97681091,\n",
       "        0.97981431, 0.97506454, 0.97653158, 0.97918565, 0.97506464,\n",
       "        0.97646172, 0.97841742, 0.97520428, 0.9759727 , 0.9793952 ,\n",
       "        0.97380721, 0.97401737, 0.97646168, 0.97653139, 0.97681098,\n",
       "        0.9754139 , 0.96109779, 0.97660139, 0.97436573, 0.90898933,\n",
       "        0.97632189, 0.9766711 , 0.90898933, 0.9777189 , 0.97681111,\n",
       "        0.97604261, 0.97792838, 0.97436592, 0.92233198, 0.97653141,\n",
       "        0.96996668, 0.90898933, 0.97764905, 0.95383095, 0.90898933,\n",
       "        0.97695043, 0.97129366, 0.90898933, 0.97702048, 0.97702031,\n",
       "        0.97471543, 0.97820785, 0.97583289, 0.97359772, 0.97723003,\n",
       "        0.97597287, 0.9732487 , 0.97583299, 0.97785859, 0.97492485,\n",
       "        0.97799816, 0.97513449, 0.97199123, 0.97632189, 0.97527418,\n",
       "        0.97422628, 0.97604241, 0.97303881, 0.97338834, 0.9779985 ,\n",
       "        0.97220039, 0.96276982, 0.97688091, 0.97667129, 0.97317872,\n",
       "        0.97778859, 0.97667129, 0.97597256, 0.97764907, 0.96332855,\n",
       "        0.97520428, 0.97681081, 0.97632179, 0.9754139 , 0.97688074,\n",
       "        0.97674093, 0.9756933 , 0.97764897, 0.97611237, 0.97513474,\n",
       "        0.97695053, 0.94796488, 0.97492507, 0.97597251, 0.97576308,\n",
       "        0.97415667, 0.97660129, 0.96214096, 0.97541395, 0.97716002,\n",
       "        0.97646163, 0.97415655, 0.97702026]),\n",
       " 'std_test_score': array([0.00178019, 0.0017753 , 0.00150617, 0.00196943, 0.00163097,\n",
       "        0.00245053, 0.02782991, 0.02664441, 0.00199134, 0.00178613,\n",
       "        0.02720315, 0.00113267, 0.00179908, 0.00251342, 0.00135221,\n",
       "        0.0017986 , 0.00118268, 0.00235041, 0.0024048 , 0.00225879,\n",
       "        0.00267244, 0.00284827, 0.00253798, 0.00243285, 0.00156073,\n",
       "        0.00263357, 0.00427167, 0.00089658, 0.00099772, 0.00153676,\n",
       "        0.00167546, 0.02614922, 0.00172302, 0.00326873, 0.00016114,\n",
       "        0.00111242, 0.00189203, 0.00016114, 0.00164247, 0.00239191,\n",
       "        0.0017172 , 0.00155191, 0.00551726, 0.02678402, 0.00196799,\n",
       "        0.00661038, 0.00016114, 0.00124772, 0.02686323, 0.00016114,\n",
       "        0.00178116, 0.00988972, 0.00016114, 0.00158129, 0.00034311,\n",
       "        0.00168968, 0.00241457, 0.00215747, 0.00234483, 0.00243236,\n",
       "        0.00168427, 0.00343974, 0.00097136, 0.0017602 , 0.00241442,\n",
       "        0.00316259, 0.00159848, 0.00386753, 0.00086573, 0.00111227,\n",
       "        0.00224775, 0.00201997, 0.00418347, 0.00051   , 0.00404089,\n",
       "        0.01164555, 0.02249817, 0.00274225, 0.0024214 , 0.0002629 ,\n",
       "        0.00256276, 0.00237059, 0.00178678, 0.00175137, 0.02730918,\n",
       "        0.00222013, 0.00160134, 0.00199319, 0.0010012 , 0.00191654,\n",
       "        0.00129911, 0.00113772, 0.00160757, 0.00279903, 0.00390781,\n",
       "        0.00136088, 0.03181571, 0.00315632, 0.00193186, 0.00193317,\n",
       "        0.00272236, 0.00160699, 0.02651477, 0.00288367, 0.00199484,\n",
       "        0.00142319, 0.00190065, 0.00177338]),\n",
       " 'rank_test_score': array([  5,  63,  20,   3,  60,  39,  94,  98,  41,   7, 102,  47,   2,\n",
       "         67,  31,   1,  74,  40,   6,  73,  44,   8,  69,  55,   4,  84,\n",
       "         83,  45,  43,  30,  65,  99,  37,  79, 104,  49,  36, 104,  15,\n",
       "         29,  52,  12,  78, 103,  42,  93, 104,  17, 100, 104,  26,  92,\n",
       "        104,  22,  23,  77,   9,  59,  85,  19,  54,  87,  58,  13,  76,\n",
       "         11,  72,  91,  48,  68,  80,  53,  89,  86,  10,  90,  96,  27,\n",
       "         34,  88,  14,  34,  56,  16,  95,  70,  32,  50,  65,  28,  33,\n",
       "         62,  18,  51,  71,  25, 101,  75,  57,  61,  81,  38,  97,  64,\n",
       "         21,  46,  82,  24])}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "### NEW ADDITIONS HERE\n",
    "\n",
    "######## This block alone took about 20 minutes to run on Nic's laptop.(Only other things running was google chrome with 6 tabs open)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# start with Neural Networks\n",
    "\n",
    "# with grid search the first parameter is the type of machine learning algorithm\n",
    "# the second parameter is the grid (which will include a list of parameters)\n",
    "\n",
    "grid_search1 = GridSearchCV(MLPClassifier(),{\n",
    "    'hidden_layer_sizes': [(10), (10,10), (10,10,10), (10,10,10,10), (5), (5,5), (5,5,5), (5,5,5,5), (5,10,5)],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam']\n",
    "}, cv=5, return_train_score=False)\n",
    "\n",
    "grid_search1.fit(x_train, y_train)\n",
    "grid_search1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "15       0.856684      0.023415         0.002808        0.000794   \n",
       "12       0.549543      0.034719         0.002605        0.000487   \n",
       "3        1.085896      0.174112         0.002992        0.000631   \n",
       "24       1.366200      0.029881         0.002808        0.000424   \n",
       "0        0.724238      0.031295         0.003212        0.000388   \n",
       "\n",
       "   param_activation param_hidden_layer_sizes param_solver  \\\n",
       "15         identity                   (5, 5)        lbfgs   \n",
       "12         identity                        5        lbfgs   \n",
       "3          identity                 (10, 10)        lbfgs   \n",
       "24         identity               (5, 10, 5)        lbfgs   \n",
       "0          identity                       10        lbfgs   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "15  {'activation': 'identity', 'hidden_layer_sizes...           0.980796   \n",
       "12  {'activation': 'identity', 'hidden_layer_sizes...           0.981494   \n",
       "3   {'activation': 'identity', 'hidden_layer_sizes...           0.981494   \n",
       "24  {'activation': 'identity', 'hidden_layer_sizes...           0.980796   \n",
       "0   {'activation': 'identity', 'hidden_layer_sizes...           0.981844   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "15           0.977304           0.981488           0.981488   \n",
       "12           0.977304           0.981488           0.980789   \n",
       "3            0.976257           0.981139           0.980440   \n",
       "24           0.976955           0.981139           0.979742   \n",
       "0            0.976606           0.980091           0.980091   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "15           0.977995         0.979814        0.001799                1  \n",
       "12           0.977995         0.979814        0.001799                2  \n",
       "3            0.978344         0.979535        0.001969                3  \n",
       "24           0.978344         0.979395        0.001561                4  \n",
       "0            0.978344         0.979395        0.001780                5  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_activation</th>\n      <th>param_hidden_layer_sizes</th>\n      <th>param_solver</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>0.856684</td>\n      <td>0.023415</td>\n      <td>0.002808</td>\n      <td>0.000794</td>\n      <td>identity</td>\n      <td>(5, 5)</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n      <td>0.980796</td>\n      <td>0.977304</td>\n      <td>0.981488</td>\n      <td>0.981488</td>\n      <td>0.977995</td>\n      <td>0.979814</td>\n      <td>0.001799</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.549543</td>\n      <td>0.034719</td>\n      <td>0.002605</td>\n      <td>0.000487</td>\n      <td>identity</td>\n      <td>5</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n      <td>0.981494</td>\n      <td>0.977304</td>\n      <td>0.981488</td>\n      <td>0.980789</td>\n      <td>0.977995</td>\n      <td>0.979814</td>\n      <td>0.001799</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.085896</td>\n      <td>0.174112</td>\n      <td>0.002992</td>\n      <td>0.000631</td>\n      <td>identity</td>\n      <td>(10, 10)</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n      <td>0.981494</td>\n      <td>0.976257</td>\n      <td>0.981139</td>\n      <td>0.980440</td>\n      <td>0.978344</td>\n      <td>0.979535</td>\n      <td>0.001969</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>1.366200</td>\n      <td>0.029881</td>\n      <td>0.002808</td>\n      <td>0.000424</td>\n      <td>identity</td>\n      <td>(5, 10, 5)</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n      <td>0.980796</td>\n      <td>0.976955</td>\n      <td>0.981139</td>\n      <td>0.979742</td>\n      <td>0.978344</td>\n      <td>0.979395</td>\n      <td>0.001561</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.724238</td>\n      <td>0.031295</td>\n      <td>0.003212</td>\n      <td>0.000388</td>\n      <td>identity</td>\n      <td>10</td>\n      <td>lbfgs</td>\n      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n      <td>0.981844</td>\n      <td>0.976606</td>\n      <td>0.980091</td>\n      <td>0.980091</td>\n      <td>0.978344</td>\n      <td>0.979395</td>\n      <td>0.001780</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Need a better way to look at results\n",
    "# you can store these in a pandas dataframe\n",
    "\n",
    "df = pd.DataFrame(grid_search1.cv_results_)\n",
    "df = df.sort_values(by=['rank_test_score'], axis=0, ascending=True) # sort by best rank\n",
    "# save the data into a csv file\n",
    "df.to_csv('\\gridsearch1.csv', index=False)\n",
    "df[df['rank_test_score'] <= 5] # this prints the 5 best scoring parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So from this test, we can improve upon our previous test score using the following parameters\n",
    "# param_activation = identity\n",
    "# param_hidden_layer_sizes = (5,5)\n",
    "# param_solver = lbfgs\n",
    "\n",
    "# the results are so close however that there will be different maximum parameters each time you run it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Accuracy Score: 0.9756983240223464\n",
      "Confusion Matrix: \n",
      "[[3225   19]\n",
      " [  68  268]]\n",
      "F1 Score: [0.98669114 0.86035313]\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# lets test it out!\n",
    "\n",
    "grid1 = MLPClassifier(activation='identity', hidden_layer_sizes=(5,5), solver='lbfgs')\n",
    "\n",
    "grid1.fit(x_train, y_train)\n",
    "y_predict = grid1.predict(x_test)\n",
    "\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle this neural network as gridsearch2.pk\n",
    "import pickle\n",
    "with open(os.path.join(here, 'gridsearch1.pkl'), 'wb') as f1:\n",
    "    pickle.dump(grid1, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-ed0f6272e102>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m }, cv=5, return_train_score=False)\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mgrid_search2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \"\"\"\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[1;31m# Run the LBFGS solver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001b[0m\u001b[0;32m    405\u001b[0m                             intercept_grads, layer_units)\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[0miprint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m         opt_res = scipy.optimize.minimize(\n\u001b[0m\u001b[0;32m    491\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_grad_lbfgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpacked_coef_inter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L-BFGS-B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    617\u001b[0m                                   **options)\n\u001b[0;32m    618\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    620\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    621\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[1;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[0m\u001b[0;32m    209\u001b[0m             X, y, activations, deltas, coef_grads, intercept_grads)\n\u001b[0;32m    210\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;31m# sigmoid and binary cross entropy, softmax and categorical cross\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;31m# entropy, and identity with squared loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlast\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[1;31m# Compute gradient for the last layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use what I already found for activation and solver and try to find a better number of hidden layers\n",
    "# took 17 minutes to run\n",
    "grid_search2 = GridSearchCV(MLPClassifier(activation=\"identity\", solver='lbfgs'),{\n",
    "    'hidden_layer_sizes': [2, (2,2), (2,2,2), (2,2,2,2), (2,2,2,2,2),\n",
    "                           3, (3,3), (3,3,3), (3,3,3,3), (3,3,3,3,3),\n",
    "                           4, (4,4), (4,4,4), (4,4,4,4), (4,4,4,4,4),\n",
    "                           5, (5,5), (5,5,5), (5,5,5,5), (5,5,5,5,5),\n",
    "                           6, (6,6), (6,6,6), (6,6,6,6), (6,6,6,6,6),\n",
    "                           7, (7,7), (7,7,7), (7,7,7,7), (7,7,7,7,7),\n",
    "                           8, (8,8), (8,8,8), (8,8,8,8), (8,8,8,8,8),\n",
    "                           9, (9,9), (9,9,9), (9,9,9,9), (9,9,9,9,9),\n",
    "                           10, (10,10), (10,10,10), (10,10,10,10), (10,10,10,10,10),\n",
    "                           11, (11,11) ,(11,11,11), (11,11,11,11), (11,11,11,11,11),\n",
    "                           12, (12,12), (12,12,12), (12,12,12,12), (12,12,12,12,12),\n",
    "                           13, (13,13), (13,13,13), (13,13,13,13), (13,13,13,13,13),\n",
    "                           14, (14,14), (14,14,14), (14,14,14,14), (14,14,14,14,14),\n",
    "                           15, (15,15), (15,15,15), (15,15,15,15), (15,15,15,15,15),\n",
    "                           100, (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)],\n",
    "}, cv=5, return_train_score=False)\n",
    "\n",
    "grid_search2.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "62       2.427366      0.116324         0.002992    4.523674e-07   \n",
       "42       1.573792      0.185290         0.003300    4.203464e-04   \n",
       "72      19.287618      1.050075         0.008976    6.307512e-04   \n",
       "50       0.975182      0.055940         0.002794    4.156154e-04   \n",
       "40       0.718044      0.070406         0.002332    4.227207e-04   \n",
       "45       0.743752      0.039658         0.002853    2.853135e-04   \n",
       "\n",
       "   param_hidden_layer_sizes                                   params  \\\n",
       "62             (14, 14, 14)     {'hidden_layer_sizes': (14, 14, 14)}   \n",
       "42             (10, 10, 10)     {'hidden_layer_sizes': (10, 10, 10)}   \n",
       "72          (100, 100, 100)  {'hidden_layer_sizes': (100, 100, 100)}   \n",
       "50                       12               {'hidden_layer_sizes': 12}   \n",
       "40                       10               {'hidden_layer_sizes': 10}   \n",
       "45                       11               {'hidden_layer_sizes': 11}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "62           0.981145           0.977304           0.981139   \n",
       "42           0.981145           0.976955           0.981488   \n",
       "72           0.981844           0.977654           0.981139   \n",
       "50           0.981844           0.976257           0.981139   \n",
       "40           0.981145           0.977304           0.981139   \n",
       "45           0.981844           0.976606           0.981139   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "62           0.982885           0.979043         0.980303        0.001932   \n",
       "42           0.981837           0.979043         0.980094        0.001846   \n",
       "72           0.981837           0.977995         0.980094        0.001874   \n",
       "50           0.981837           0.979043         0.980024        0.002144   \n",
       "40           0.981837           0.978694         0.980024        0.001729   \n",
       "45           0.981837           0.978694         0.980024        0.002064   \n",
       "\n",
       "    rank_test_score  \n",
       "62                1  \n",
       "42                2  \n",
       "72                3  \n",
       "50                4  \n",
       "40                5  \n",
       "45                5  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_hidden_layer_sizes</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>62</th>\n      <td>2.427366</td>\n      <td>0.116324</td>\n      <td>0.002992</td>\n      <td>4.523674e-07</td>\n      <td>(14, 14, 14)</td>\n      <td>{'hidden_layer_sizes': (14, 14, 14)}</td>\n      <td>0.981145</td>\n      <td>0.977304</td>\n      <td>0.981139</td>\n      <td>0.982885</td>\n      <td>0.979043</td>\n      <td>0.980303</td>\n      <td>0.001932</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>1.573792</td>\n      <td>0.185290</td>\n      <td>0.003300</td>\n      <td>4.203464e-04</td>\n      <td>(10, 10, 10)</td>\n      <td>{'hidden_layer_sizes': (10, 10, 10)}</td>\n      <td>0.981145</td>\n      <td>0.976955</td>\n      <td>0.981488</td>\n      <td>0.981837</td>\n      <td>0.979043</td>\n      <td>0.980094</td>\n      <td>0.001846</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>19.287618</td>\n      <td>1.050075</td>\n      <td>0.008976</td>\n      <td>6.307512e-04</td>\n      <td>(100, 100, 100)</td>\n      <td>{'hidden_layer_sizes': (100, 100, 100)}</td>\n      <td>0.981844</td>\n      <td>0.977654</td>\n      <td>0.981139</td>\n      <td>0.981837</td>\n      <td>0.977995</td>\n      <td>0.980094</td>\n      <td>0.001874</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>0.975182</td>\n      <td>0.055940</td>\n      <td>0.002794</td>\n      <td>4.156154e-04</td>\n      <td>12</td>\n      <td>{'hidden_layer_sizes': 12}</td>\n      <td>0.981844</td>\n      <td>0.976257</td>\n      <td>0.981139</td>\n      <td>0.981837</td>\n      <td>0.979043</td>\n      <td>0.980024</td>\n      <td>0.002144</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.718044</td>\n      <td>0.070406</td>\n      <td>0.002332</td>\n      <td>4.227207e-04</td>\n      <td>10</td>\n      <td>{'hidden_layer_sizes': 10}</td>\n      <td>0.981145</td>\n      <td>0.977304</td>\n      <td>0.981139</td>\n      <td>0.981837</td>\n      <td>0.978694</td>\n      <td>0.980024</td>\n      <td>0.001729</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.743752</td>\n      <td>0.039658</td>\n      <td>0.002853</td>\n      <td>2.853135e-04</td>\n      <td>11</td>\n      <td>{'hidden_layer_sizes': 11}</td>\n      <td>0.981844</td>\n      <td>0.976606</td>\n      <td>0.981139</td>\n      <td>0.981837</td>\n      <td>0.978694</td>\n      <td>0.980024</td>\n      <td>0.002064</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df = pd.DataFrame(grid_search2.cv_results_)\n",
    "df = df.sort_values(['rank_test_score'], ascending=True, axis=0)\n",
    "\n",
    "df.to_csv('gridsearch2.csv', index=True)\n",
    "df[df['rank_test_score'] <= 5] # this prints the 5 best scoring parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Accuracy Score: 0.9762569832402235\n",
      "Confusion Matrix: \n",
      "[[3225   19]\n",
      " [  66  270]]\n",
      "F1 Score: [0.98699311 0.864     ]\n",
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "grid2 = MLPClassifier(activation='identity', hidden_layer_sizes=(14,14,14), solver='lbfgs')\n",
    "\n",
    "grid2.fit(x_train, y_train)\n",
    "y_predict = grid2.predict(x_test)\n",
    "\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"F1 Score:\", end =\" \")\n",
    "print(f1_score(y_test, y_predict, average=None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle this neural network as gridsearch2.pkl\n",
    "with open(os.path.join(here, 'gridsearch2.pkl'), 'wb') as f2:\n",
    "    pickle.dump(grid2, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nnull\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "Accuracy Score: 0.908989313403646\n",
      "Confusion Matrix:\n",
      "[[13014  1303]\n",
      " [    0     0]]\n",
      "f1 Score: [0.9523252 0.       ]\n"
     ]
    }
   ],
   "source": [
    "# pick the worst performer and pickle to compare\n",
    "# this one was so bad because it predicted all were non-pulsar\n",
    "worst_model = MLPClassifier(activation='logistic', hidden_layer_sizes=(10,10,10), solver='sgd')\n",
    "\n",
    "worst_model.fit(x_train, y_train)\n",
    "y_predict = worst_model.predict(x_train)\n",
    "\n",
    "print('Accuracy Score: ' + str(accuracy_score(y_predict, y_train)))\n",
    "print('Confusion Matrix:\\n' + str(confusion_matrix(y_predict, y_train)))\n",
    "print('f1 Score: ' + str(f1_score(y_predict, y_train, average=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad pickle\n",
    "with open(os.path.join(here, 'worst_model.pkl'), 'wb') as f3:\n",
    "    pickle.dump(worst_model, f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}